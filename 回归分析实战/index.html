<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>回归分析实战 | 小明的博客</title><meta name="author" content="爱编程的小明"><meta name="copyright" content="爱编程的小明"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#e68ab8"><meta name="description" content="回归分析 线性回归 scikit-learn提供了广义线性模型模块sklearn.linear_model. 它定义线性模型为：  linear_model模块提供用于线性回归的类： class sklearn.linear_model.LinearRegression(fit_intercept&amp;#x3D;"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kobal.top/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4e3a07c287f8fb6cfc09bf5a7fdc1dd7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "e8bjif1knd");</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":120},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '回归分析实战',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-02 12:31:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#e68ab8')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><style>#article-container.post-content h1:before, h2:before, h3:before, h4:before, h5:before, h6:before { -webkit-animation: avatar_turn_around 1s linear infinite; -moz-animation: avatar_turn_around 1s linear infinite; -o-animation: avatar_turn_around 1s linear infinite; -ms-animation: avatar_turn_around 1s linear infinite; animation: avatar_turn_around 1s linear infinite; }</style><link rel="stylesheet" href="/Scripts/css/transparent.css"><link rel="stylesheet" href="/Scripts/css/font.css"><link rel="stylesheet" href="/Scripts/css/foot_style.css"><link rel="stylesheet" href="/Scripts/css/twikoo_beautify.css"><link rel="stylesheet" href="/Scripts/css/tags.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/animate.css/4.1.1/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i><span> 壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i><span> 开往</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="小明的博客"><span class="site-name">小明的博客</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i><span> 壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i><span> 开往</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">回归分析实战<a class="post-edit-link" href="https://github.dev/kebuAAA/myblog/blob/main/source/_posts/回归分析实战.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-01T04:31:00.000Z" title="发表于 2022-03-01 12:31:00">2022-03-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-02T04:31:00.000Z" title="更新于 2022-03-02 12:31:00">2022-03-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BC%96%E7%A8%8B/">编程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="回归分析实战"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="回归分析">回归分析</h2>
<h3 id="线性回归">线性回归</h3>
<p>scikit-learn提供了广义线性模型模块sklearn.linear_model. 它定义线性模型为：<br>
<img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/0.png" alt="image.png"><br>
linear_model模块提供用于线性回归的类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.linear_model.LinearRegression(fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, n_jobs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>生成一个LinearRegression类的实例。</li>
<li>使用该实例调用<code>fit()</code>方法来拟合数组 X, y</li>
<li>fit(X, y, sample_weight=None)，其中X, y接收数组，分别代表训练集和目标。</li>
<li>将线性模型的系数w存储在其成员变量coef_中。</li>
<li>用户可通过访问coef_和intercept_观察拟合的方程中，各自变量的系数和截距。</li>
<li>使用<code>predict()</code>方法能够预测一个新的样本的回归值：</li>
<li>predict(X)，其中X是新的样本。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ch7</span></span><br><span class="line"><span class="comment">#例7-1 读取第5章产生的1元线性回归数据，进行回归分析，可视化回归结果</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment">#读取数据文件</span></span><br><span class="line">path=<span class="string">&#x27;D:/my_python/ch7/data/&#x27;</span></span><br><span class="line">X = pd.read_csv(path+<span class="string">&#x27;1x_regression.csv&#x27;</span>,sep = <span class="string">&#x27;,&#x27;</span>,encoding = <span class="string">&#x27;utf-8&#x27;</span>).values</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span><span class="comment">#设置字体为SimHei显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span><span class="comment">#坐标轴刻度显示负号</span></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">14</span>)<span class="comment">#设置图中字号大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据散点图&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)<span class="comment">#添加横轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)<span class="comment">#添加纵轴标签</span></span><br><span class="line"><span class="comment">#绘制原始数据散点图，观察其特征</span></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line">lr = LinearRegression()<span class="comment">#生成线性回归模型实例</span></span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">lr.fit(X[:,<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">1</span>), X[:,<span class="number">1</span>].reshape(-<span class="number">1</span>,<span class="number">1</span>))<span class="comment">#训练</span></span><br><span class="line"><span class="comment">#将原始数据与回归曲线画在一张图上</span></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>])</span><br><span class="line">plt.plot(X[:,<span class="number">0</span>], lr.predict(X[:,<span class="number">0</span>].reshape(-<span class="number">1</span>,<span class="number">1</span>)), <span class="string">&#x27;k-&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据与回归方程图&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)<span class="comment">#添加横轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)<span class="comment">#添加纵轴标签</span></span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;回归方程为：\n&#x27;</span>,<span class="string">&#x27;y=&#x27;</span>,lr.coef_[<span class="number">0</span>],<span class="string">&#x27;*x+&#x27;</span>,lr.intercept_[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x=&#x27;</span>,x,<span class="string">&#x27;时，y的预测值为：&#x27;</span>,lr.predict(x))</span><br></pre></td></tr></table></figure>
<h3 id="岭回归">岭回归</h3>
<p>scikit-learn的sklearn.linear_model模块提供了岭回归<code>Ridge()</code>类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.linear_model.Ridge(alpha=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, max_iter=<span class="literal">None</span>, tol=<span class="number">0.001</span>, solver=’auto’, random_state=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>其主要参数alpha即为上式中的我们所说的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>.<br>
<code>Ridge()</code>类的主要属性有：<br>
coef_ : 数组，形状为(n_features,)或(n_targets, n_features)，表示权重向量。<br>
intercept_ : 浮点数，表示截距。<br>
n_iter_ : 数组，形状为(n_targets,)，表示每个目标的迭代次数，可以是None。<br>
<code>Ridge()</code>类的主要方法有：<br>
fit(X, y[, sample_weight])——拟合岭回归模型。<br>
get_params([deep])——获取估计器参数。<br>
predict(X)——预测X中样本的回归值。<br>
score(X, y[, sample_weight])——返回R^2决策系数的预测值。<br>
set_params(**params)——设置估计器参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">岭回归</span><br><span class="line"><span class="comment">#例7-4 生成具有共线性特征的分类数据集，以对各个特征设置系数，叠加噪声，生成回归目标，进行岭回归</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">n_samples=<span class="number">100</span></span><br><span class="line"><span class="comment">#生成具有冗余特征（共线性）的分类样本集</span></span><br><span class="line">X, y = datasets.make_classification(n_samples=n_samples, n_features=<span class="number">10</span>,</span><br><span class="line">                                   n_informative=<span class="number">2</span>, n_redundant=<span class="number">7</span>,</span><br><span class="line">                                    n_classes=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.pairplot(pd.DataFrame(X))</span><br><span class="line"><span class="comment">#为X的每个特征设置系数和截距</span></span><br><span class="line">b,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9=<span class="number">3</span>,-<span class="number">5</span>,<span class="number">4</span>,<span class="number">8</span>,-<span class="number">9</span>,-<span class="number">3</span>,<span class="number">6</span>,<span class="number">2</span>,-<span class="number">1</span>,<span class="number">3</span>,<span class="number">7</span></span><br><span class="line">noise=np.random.randn(n_samples)</span><br><span class="line"><span class="comment">#叠加噪声生成回归目标集</span></span><br><span class="line">y=<span class="number">2</span>*noise+b+a0*X[:,<span class="number">0</span>]+a1*X[:,<span class="number">1</span>]+a2*X[:,<span class="number">2</span>]+a3*X[:,<span class="number">3</span>]+a4*X[:,<span class="number">4</span>]+\</span><br><span class="line">a5*X[:,<span class="number">5</span>]+a6*X[:,<span class="number">6</span>]+a7*X[:,<span class="number">7</span>]+a8*X[:,<span class="number">8</span>]+a9*X[:,<span class="number">9</span>]</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="comment">#可视化,绘制真实系数与回归分析系数对比图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">4</span>))</span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">14</span>)<span class="comment">#设置图中字号大小</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span><span class="comment">#设置字体为SimHei显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span><span class="comment">#坐标轴刻度显示负号</span></span><br><span class="line">plt.plot([b,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9],marker=<span class="string">&#x27;o&#x27;</span>)<span class="comment">#真实系数</span></span><br><span class="line">label=[]<span class="comment">#该行代码书本中没有，应添加</span></span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> [<span class="number">0.001</span>,<span class="number">100</span>,<span class="number">1000</span>]:</span><br><span class="line">    ridge = linear_model.Ridge(alpha=alpha)</span><br><span class="line">    ridge.fit(X, y)<span class="comment">#拟合模型</span></span><br><span class="line">    plt.plot(np.append(ridge.intercept_,ridge.coef_),marker=<span class="string">&#x27;*&#x27;</span>)<span class="comment">#拟合系数</span></span><br><span class="line">    np.append(label,np.str_(alpha))</span><br><span class="line">plt.legend([<span class="string">&#x27;实际系数&#x27;</span>,<span class="string">&#x27;alpha=0.001&#x27;</span>, <span class="string">&#x27;alpha=100&#x27;</span>,<span class="string">&#x27;alpha=1000&#x27;</span>])</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">20</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;拟合系数与实际系数对比&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;变量Xi&#x27;</span>)<span class="comment">#添加横轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;变量Xi的系数&#x27;</span>)<span class="comment">#添加纵轴标签</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/1.png" alt="image.png"></p>
<h3 id="逻辑回归">逻辑回归</h3>
<p>实现方面，逻辑回归只是对对线性回归的计算结果加上了一个Sigmoid函数，将数值结果转化为了0到1之间的概率(数值越大，函数越逼近1；数值越小，函数越逼近0)，根据这个概率预测样本的类别。<br>
scikit-learn机器学习模块的sklearn.linear_model提供了逻辑回归类<code>LogisticRegression()</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.linear_model.LogisticRegression(penalty=’l2’, dual=<span class="literal">False</span>, tol=<span class="number">0.0001</span>, C=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>, class_weight=<span class="literal">None</span>, random_state=<span class="literal">None</span>, solver=’warn’, max_iter=<span class="number">100</span>, multi_class=’warn’, verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>, n_jobs=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>penalty：惩罚项，str类型，可选参数为l1和l2，默认为l2。用于指定惩罚项中使用的规范。newton-cg、sag和lbfgs求解算法只支持l2规范。<br>
multi_class：分类方式选择参数，str类型，可选参数为ovr和multinomial，默认为ovr。ovr即前面提到的one-vs-rest(OvR)，而multinomial即前面提到的many-vs-many(MvM)。如果是二元逻辑回归，ovr和multinomial并没有任何区别，区别主要在多元逻辑回归上。<br>
<code>LogisticRegression()</code>类的<strong>主要属性</strong>有：<br>
classes_ : 数组, 形状为(n_classes, )，表示分类器的类标签列表。<br>
coef_ : 数组, 形状为((1, n_features)或 (n_classes, n_features)，表示决策函数中特征的系数。<br>
intercept_ : 数组, 形状为(1,)或(n_classes,)，表示决策函数的截距。<br>
n_iter_ : 数组, 形状为(n_classes,)或(1, )，表示所有类的实际迭代次数。<br>
<code>LogisticRegression()</code>类的<strong>主要方法</strong>有：<br>
decision_function(X)——预测样本的置信度分数。<br>
densify()——将系数矩阵转化为紧密数组的格式。<br>
fit(X, y[, sample_weight])——对给定训练数据拟合模型。<br>
get_params([deep])	——获取估计器参数。<br>
predict(X)——预测X中样本的类标签。<br>
predict_log_proba(X)——估计概率对数。<br>
predict_proba(X)——估计概率。<br>
score(X, y[, sample_weight])	——返回对测试集的平均分类准确率。<br>
set_params(**params)——设置估计器参数。<br>
sparsify()	——将系数矩阵转化为稀疏格式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#逻辑回归</span></span><br><span class="line"><span class="comment">#例7-5 生成具有两个特征的二元分类样本，分类别绘制原始样本集散点图，</span></span><br><span class="line"><span class="comment">#使用样本集训练逻辑回归模型，用训练好的模型对样本集进行分类，观察分类结果</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="comment">#使用make_blobs生成centers个类的数据集X，X形状为(n_samples,n_features)</span></span><br><span class="line"><span class="comment">#指定每个类的中心位置，y返回类标签</span></span><br><span class="line">centers = [(-<span class="number">2</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">0</span>)]</span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=centers, n_features=<span class="number">2</span>,</span><br><span class="line">                   random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#分类别可视化样本集</span></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">14</span>)<span class="comment">#设置图中字号大小</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span><span class="comment">#设置字体为SimHei显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span><span class="comment">#坐标轴刻度显示负号</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">plt.scatter(X[np.where(y==<span class="number">0</span>),<span class="number">0</span>],X[np.where(y==<span class="number">0</span>),<span class="number">1</span>],marker=<span class="string">&#x27;o&#x27;</span>,c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.scatter(X[np.where(y==<span class="number">1</span>),<span class="number">0</span>],X[np.where(y==<span class="number">1</span>),<span class="number">1</span>],marker=<span class="string">&#x27;&lt;&#x27;</span>,c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">plt.ylim(-<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;y=0&#x27;</span>,<span class="string">&#x27;y=1&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;使用make_blobs生成自定义中心的2类样本&#x27;</span>)<span class="comment">#添加标题</span></span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#训练逻辑回归模型</span></span><br><span class="line">logi_reg = LogisticRegression(random_state=<span class="number">0</span>, solver=<span class="string">&#x27;lbfgs&#x27;</span>,</span><br><span class="line">                         multi_class=<span class="string">&#x27;multinomial&#x27;</span>).fit(X, y)</span><br><span class="line"><span class="comment">#使用训练好的模型预测X的每个样本类别</span></span><br><span class="line">y_predict=logi_reg.predict(X)</span><br><span class="line"><span class="comment">#分类别可视化预测结果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">plt.scatter(X[np.where(y_predict==<span class="number">0</span>),<span class="number">0</span>],X[np.where(y_predict==<span class="number">0</span>),<span class="number">1</span>],marker=<span class="string">&#x27;o&#x27;</span>,c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.scatter(X[np.where(y_predict==<span class="number">1</span>),<span class="number">0</span>],X[np.where(y_predict==<span class="number">1</span>),<span class="number">1</span>],marker=<span class="string">&#x27;&lt;&#x27;</span>,c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">plt.ylim(-<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;y_predict=0&#x27;</span>,<span class="string">&#x27;y_predict=1&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;对X预测结果&#x27;</span>)<span class="comment">#添加标题</span></span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#绘制预测错误样本</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">plt.scatter(X[np.where(y_predict!=y),<span class="number">0</span>],X[np.where(y_predict!=y),<span class="number">1</span>],marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;预测错误的样本&#x27;</span>)<span class="comment">#添加标题</span></span><br><span class="line">plt.xlim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">plt.ylim(-<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="多项式回归">多项式回归</h3>
<p>scikit-learn对多项式回归没有提供直接的方法，而是在数据预处理模块sklearn.preprocessing提供了<code>PolynomialFeatures()</code>类。<br>
该类将数据集变换为具有高次项特征的新的数据集，将原始问题转化为线性回归问题。<br>
用户再使用线性回归方法对转化后的数据集进行训练，从而间接的进行多项式回归分析。<br>
<img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/2.png" alt="image.png"><br>
PolynomialFeatures()类将其转化为具有3个特征的线性回归问题，这三个特征分别是x, x2, 和一个值全为1的常量特征。<br>
输出形状为(n_samples,3), 格式为[1, x,x2]的新的数据集。<br>
这时，新的数据集将是一个线性回归问题。使用线性回归方法对其拟合，既可以得到回归模型。<br>
对多特征、有更高次项的样本，PolynomialFeatures()类同样通过增加高次项特征的方法，将其转化为线性特征数据集。<br>
要预测新值，也需要使用训练的PolynomialFeatures()模型将其转为线性数据集，然后使用训练的线性回归模型对转化后的数据集进行预测。<br>
<code>PolynomialFeatures()</code>类的格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.preprocessing.PolynomialFeatures(degree=<span class="number">2</span>, interaction_only=<span class="literal">False</span>, include_bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>参数degree接收整数，表示拟合目标中项的最高指数，默认为2。<br>
PolynomialFeatures()类的主要参数如下：<br>
powers_ : 数组，形状为(n_output_features, n_input_features)，powers_[i, j]是第j个输入特征在第i个输出特征的指数。<br>
n_input_features_ :输入特征的数量。<br>
n_output_features_ : 输出的多项式特征的总数量。<br>
PolynomialFeatures()类的<strong>主要方法</strong>如下：<br>
fit(X[, y])——计算输出特征的数量。<br>
fit_transform(X[, y])——拟合数据，并转化数据。<br>
get_feature_names([input_features])——返回输出特征的名称。<br>
get_params([deep])——获取估计器参数。<br>
set_params(**params)——设置估计器参数。<br>
transform(X)——将数据集转化为多项式特征。<br>
先生成PolynomialFeatures（）类的一个实例，然后使用fit()输出特征的数量再使用transform（）将数据集转换为1次特征数据集(也可以使用fit_transform()）拟合和转换数据，接着对转换后的数据进行线性回归。</p>
<h4 id="单特征数据集多项式回归">单特征数据集多项式回归</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#多项式回归</span></span><br><span class="line"><span class="comment">#例7-7 根据已知一元二次方程，生成非线性样本集，对样本集进行多项式回归分析。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">n_samples=<span class="number">10</span></span><br><span class="line">X=np.sort(np.random.uniform(-<span class="number">5</span>,<span class="number">10</span>,n_samples)).reshape(-<span class="number">1</span>,<span class="number">1</span>)<span class="comment">#形状为1列（一个特征）</span></span><br><span class="line">y = <span class="number">1.5</span> * X**<span class="number">2</span> -<span class="number">5</span>*X -<span class="number">10</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span><span class="comment">#设置字体为SimHei显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span><span class="comment">#坐标轴刻度显示负号</span></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">14</span>)<span class="comment">#设置图中字号大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line">plt.title(<span class="string">&#x27;原始样本集&#x27;</span>)<span class="comment">#添加标题</span></span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">poly = PolynomialFeatures(<span class="number">2</span>)</span><br><span class="line">poly.fit(X)<span class="comment">#拟合多项式模型</span></span><br><span class="line">X2=poly.transform(X)<span class="comment">#使用拟合模型变换X</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始数据集X的形状为：\n&#x27;</span>,X.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X转换为X2后的形状为：\n&#x27;</span>,X2.shape)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始数据集X为：\n&#x27;</span>,X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X转换为X2后为：\n&#x27;</span>,X2)  </span><br><span class="line">lin_reg = LinearRegression()<span class="comment">#生成线性回归模型实例</span></span><br><span class="line">lin_reg.fit(X2,y)<span class="comment">#使用变换后的数据集拟合线性回归模型</span></span><br><span class="line"><span class="comment">#生成均匀分布、排序的测试集,排序便于绘制曲线</span></span><br><span class="line">x_test=np.sort(np.random.uniform(-<span class="number">10</span>,<span class="number">15</span>,<span class="number">100</span>))</span><br><span class="line"><span class="comment">#使用拟合的多项式模型变换测试集</span></span><br><span class="line">x_test2=poly.transform(x_test.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#使用拟合的线性回归模型预测变换后的测试集</span></span><br><span class="line">y_test_predict=lin_reg.predict(x_test2)</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">plt.plot(x_test,y_test_predict,linewidth=<span class="number">2</span>,c=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line">plt.title(<span class="string">&#x27;多项式回归结果&#x27;</span>)<span class="comment">#添加标题</span></span><br><span class="line">plt.legend([<span class="string">&#x27;n=2&#x27;</span>,<span class="string">&#x27;原始样本&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="多特征数据集多项式回归">多特征数据集多项式回归</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#二特征多项式回归</span></span><br><span class="line"><span class="comment">#例7-10 根据已知二元二次方程，生成非线性样本集，对样本集进行多项式回归分析。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">n_samples=<span class="number">30</span></span><br><span class="line">X1=np.random.uniform(-<span class="number">1</span>,<span class="number">1</span>,n_samples).reshape(-<span class="number">1</span>,<span class="number">1</span>)<span class="comment">#形状为1列（一个特征）</span></span><br><span class="line">X2=np.random.uniform(-<span class="number">1</span>,<span class="number">1</span>,n_samples).reshape(-<span class="number">1</span>,<span class="number">1</span>)<span class="comment">#形状为1列（一个特征）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X1的形状为：&#x27;</span>,X1.shape) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X2的形状为：&#x27;</span>,X2.shape) </span><br><span class="line"><span class="comment">#生成矩阵，，以生成更多空间样本</span></span><br><span class="line">X1, X2 = np.meshgrid(X1, X2)</span><br><span class="line">y =X1**<span class="number">2</span>+X2**<span class="number">2</span>+<span class="number">0.3</span>*np.random.randn(n_samples)<span class="comment">#叠加噪声</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;生成矩阵后X1的形状为：&#x27;</span>,X1.shape) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;生成矩阵后X2的形状为：&#x27;</span>,X2.shape) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y的形状为：&#x27;</span>,y.shape) </span><br><span class="line"><span class="comment">#导入3D绘图模块，绘制原始样本的3D散点图</span></span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.scatter(X1, X2,y,c=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始样本集&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment">#将X1,X2转化为单列特征，横向合并</span></span><br><span class="line">X=np.hstack((X1.reshape(-<span class="number">1</span>,<span class="number">1</span>),X2.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">poly2 = PolynomialFeatures(<span class="number">2</span>)<span class="comment">#多项式拟合模型参数最高指数为2</span></span><br><span class="line">poly2.fit(X)<span class="comment">#拟合多项式模型</span></span><br><span class="line">X_poly=poly2.transform(X)<span class="comment">#使用拟合模型变换X</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始数据集X的形状为：&#x27;</span>,X.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X转换为X_poly后的形状为：&#x27;</span>,X_poly.shape)   </span><br><span class="line">lin_reg2 = LinearRegression()<span class="comment">#生成线性回归模型实例</span></span><br><span class="line">lin_reg2.fit(X_poly,y.reshape(-<span class="number">1</span>,<span class="number">1</span>))<span class="comment">#使用变换后的数据集拟合线性回归模型</span></span><br><span class="line"><span class="comment">#生成测试集,用于预测，并绘制拟合曲面</span></span><br><span class="line">n_test_samples=<span class="number">100</span></span><br><span class="line">x_test1=np.linspace(-<span class="number">1.1</span>,<span class="number">1.1</span>,n_test_samples)</span><br><span class="line">x_test2=np.linspace(-<span class="number">1.1</span>,<span class="number">1.1</span>,n_test_samples)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x_test1的形状为：&#x27;</span>,x_test1.shape) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x_test2的形状为：&#x27;</span>,x_test2.shape) </span><br><span class="line">lin_reg2 = LinearRegression()<span class="comment">#生成线性回归模型实例</span></span><br><span class="line">lin_reg2.fit(X_poly,y.reshape(-<span class="number">1</span>,<span class="number">1</span>))<span class="comment">#使用变换后的数据集拟合线性回归模型</span></span><br><span class="line"><span class="comment">#生成测试集,用于预测，并绘制拟合曲面</span></span><br><span class="line">n_test_samples=<span class="number">100</span></span><br><span class="line">x_test1=np.linspace(-<span class="number">1.1</span>,<span class="number">1.1</span>,n_test_samples)</span><br><span class="line">x_test2=np.linspace(-<span class="number">1.1</span>,<span class="number">1.1</span>,n_test_samples)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x_test1的形状为：&#x27;</span>,x_test1.shape) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x_test2的形状为：&#x27;</span>,x_test2.shape) </span><br><span class="line"><span class="comment">#将x_test1,x_test2再转换为单列（单特征）数组，并横向合并</span></span><br><span class="line">X_test=np.hstack((x_test1.reshape(-<span class="number">1</span>,<span class="number">1</span>),x_test2.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">X_test_poly=poly2.transform(X_test)<span class="comment">#多项式特征变换</span></span><br><span class="line">y_predict=lin_reg2.predict(X_test_poly)<span class="comment">#线性回归模型预测</span></span><br><span class="line"><span class="comment">#利用预测结果绘制拟合曲面，绘制原始数据散点图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"><span class="comment">#将x_test1,x_test2恢复为矩阵形式，绘制预测结果的曲面</span></span><br><span class="line">ax.plot_surface(x_test1.reshape(-<span class="number">1</span>,n_test_samples),</span><br><span class="line">                x_test2,y_predict.reshape(-<span class="number">1</span>,n_test_samples),</span><br><span class="line">                color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax.scatter(X1, X2,y,c=<span class="string">&#x27;y&#x27;</span>)<span class="comment">#绘制原始数据</span></span><br><span class="line">plt.title(<span class="string">&#x27;原始样本集与拟合曲面&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://kobal.top">爱编程的小明</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://kobal.top/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/">https://kobal.top/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://kobal.top" target="_blank">小明的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/">回归分析</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E7%A8%8B/">机器学习编程</a></div><div class="post_share"><div class="social-share" data-image="/top_img/10055.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/" title="模型的保存与加载"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10001.webp" onerror="onerror=null;src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">模型的保存与加载</div></div></a></div><div class="next-post pull-right"><a href="/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" title="支持向量机"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10027.webp" onerror="onerror=null;src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">支持向量机</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10032.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-15</div><div class="title">Lasso回归</div></div></a></div><div><a href="/Linear%20Regression/" title="一元线性回归"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10006.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-13</div><div class="title">一元线性回归</div></div></a></div><div><a href="/Logistic%20Regression/" title="Logistic Regression"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10048.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-17</div><div class="title">Logistic Regression</div></div></a></div><div><a href="/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" title="回归分析"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10036.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-09</div><div class="title">回归分析</div></div></a></div><div><a href="/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" title="多元线性回归"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10039.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-31</div><div class="title">多元线性回归</div></div></a></div><div><a href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归"><img class="cover" src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/岭回归_20231109082818.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-08</div><div class="title">岭回归</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">爱编程的小明</div><div class="author-info__description">只要不折腾，万般可将就</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kebuAAA"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kebuAAA" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/2945190789@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/img/wechat.webp" target="_blank" title="欢迎交流"><i class="fa-brands fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">如网页加载较慢请尝试魔法上网，博客图文可能无关可以忽略</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90"><span class="toc-number">1.</span> <span class="toc-text">回归分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.1.</span> <span class="toc-text">线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B2%AD%E5%9B%9E%E5%BD%92"><span class="toc-number">1.2.</span> <span class="toc-text">岭回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">1.3.</span> <span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.</span> <span class="toc-text">多项式回归</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.1.</span> <span class="toc-text">单特征数据集多项式回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="toc-number">1.4.2.</span> <span class="toc-text">多特征数据集多项式回归</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10032.webp" onerror="this.onerror=null;this.src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="Lasso回归"/></a><div class="content"><a class="title" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归">Lasso回归</a><time datetime="2023-11-14T16:00:00.000Z" title="更新于 2023-11-15 00:00:00">2023-11-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/岭回归_20231109082818.png" onerror="this.onerror=null;this.src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="岭回归"/></a><div class="content"><a class="title" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归">岭回归</a><time datetime="2023-11-07T16:00:00.000Z" title="更新于 2023-11-08 00:00:00">2023-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/优雅论文排版_20230921093206.png" onerror="this.onerror=null;this.src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="优雅论文排版"/></a><div class="content"><a class="title" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版">优雅论文排版</a><time datetime="2023-09-20T16:00:00.000Z" title="更新于 2023-09-21 00:00:00">2023-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/多元统计分析_多元正态曲线.png" onerror="this.onerror=null;this.src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="多元统计分析"/></a><div class="content"><a class="title" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析">多元统计分析</a><time datetime="2023-06-16T02:22:54.000Z" title="更新于 2023-06-16 10:22:54">2023-06-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Hypothesis%20testing/" title="假设检验"><img src= "https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10036.webp" onerror="this.onerror=null;this.src='https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600'" alt="假设检验"/></a><div class="content"><a class="title" href="/Hypothesis%20testing/" title="假设检验">假设检验</a><time datetime="2023-05-09T02:34:00.000Z" title="更新于 2023-05-09 10:34:00">2023-05-09</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.kobal.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.kobal.top/',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.staticfile.org/twikoo/1.6.22/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script src="/Scripts/js/beijing.js"></script><script src="/Scripts/js/foot_style.js"></script><script src="/Scripts/js/fireworks.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.bootcdn.net/ajax/libs/butterfly-extsrc/1.1.3/fireworks.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '0.5s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/wow/1.1.2/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>