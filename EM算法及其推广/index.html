<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>EM算法及其推广 | 小明的博客</title><meta name="author" content="爱编程的小明"><meta name="copyright" content="爱编程的小明"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#e68ab8"><meta name="description" content="EM算法 对于一般概率模型的学习策略，我们往往会采取极大似然估计或者贝叶斯估计的方法对模型的参数进行估计，但是需要注意的是这种估计方法都是建立在待估参数全部为已经知道结果的参数的基础之上的(complete-data..."><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kebuaaa.github.io/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//www.clarity.ms"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach((([e,t])=>n.setAttribute(e,t))),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),getCSS:(e,t)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),addGlobalFn:(e,t,o=!1,a=window)=>{const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#e68ab8")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>var _hmt=_hmt||[];!function(){var t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4e3a07c287f8fb6cfc09bf5a7fdc1dd7";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(t,a)}(),btf.addGlobalFn("pjaxComplete",(()=>{_hmt.push(["_trackPageview",window.location.pathname])}),"baidu_analytics")</script><script>!function(e,t,n,c,a,i,r){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(i=t.createElement(c)).async=1,i.src="https://www.clarity.ms/tag/e8bjif1knd",(r=t.getElementsByTagName(c)[0]).parentNode.insertBefore(i,r)}(window,document,"clarity","script")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:{defaultEncoding:1,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!1},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"EM算法及其推广",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,isShuoshuo:!1}</script><style>#article-container.post-content h1:before,h2:before,h3:before,h4:before,h5:before,h6:before{-webkit-animation:avatar_turn_around 1s linear infinite;-moz-animation:avatar_turn_around 1s linear infinite;-o-animation:avatar_turn_around 1s linear infinite;-ms-animation:avatar_turn_around 1s linear infinite;animation:avatar_turn_around 1s linear infinite}</style><link rel="stylesheet" href="/Scripts/css/transparent.css"><link rel="stylesheet" href="/Scripts/css/font.css"><link rel="stylesheet" href="/Scripts/css/foot_style.css"><link rel="stylesheet" href="/Scripts/css/twikoo_beautify.css"><link rel="stylesheet" href="/Scripts/css/tags.css"><link rel="stylesheet" href="/Scripts/css/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet"></head><body><div id="web_bg" style="background-image:url(url(/img/index_img.webp))"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i> <span>壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i> <span>开往</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">小明的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">EM算法及其推广</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i> <span>壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i> <span>开往</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">EM算法及其推广<a class="post-edit-link" href="https://github.dev/kebuAAA/myblog/blob/main/source/_posts/EM算法及其推广.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-17T14:03:00.000Z" title="发表于 2022-03-17 22:03:00">2022-03-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-05T14:03:00.000Z" title="更新于 2023-04-05 22:03:00">2023-04-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/">基础理论</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h1 id="em算法">EM算法</h1><p>对于一般概率模型的学习策略，我们往往会采取极大似然估计或者贝叶斯估计的方法对模型的参数进行估计，但是需要注意的是这种估计方法都是建立在待估参数全部为已经知道结果的参数的基础之上的(complete-data problem)。当模型中有隐变量/潜在变量（数据不可观测的变量）时，似然函数的最大化变得困难。这是就可以使用EM算法,EM算法是在不完全数据下求解MLE估计结果的一种近似求解方法，用迭代去逼近原来不完整数据问题的结果。EM算法主要分为两步：</p><ul><li>E:求期望(expectation)</li><li>M:求极大(maximization)</li></ul><p>EM算法的核心思想是在既定样本数据下在因变量最有可能的分布状态下利用极大似然估计模型的参数。</p><h2 id="算法导出">算法导出</h2><p>针对一个含有隐变量的概率模型，这里假设隐变量为Z，观测数据Y关于参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.02778em">θ</span></span></span></span>的对数似然函数为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.02778em">θ</span><span class="mclose">)</span></span></span></span>:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: equation at position 7: \begin{̲e̲q̲u̲a̲t̲i̲o̲n̲}̲
\begin{aligned…">\begin{equation} \begin{aligned} L(\theta) &amp; = \log P(Y|\theta)=log\sum_{Z}P(Y,Z|\theta)\\ &amp;=\log\large( \sum_{Z}P(Y,Z|\theta)P(Z|\theta)\large) \end{aligned} \end{equation}</p><p>迭代主要是确定待估参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.02778em">θ</span></span></span></span>的最可能取值，记第i次迭代后的估计值为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\theta^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8879999999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: equation* at position 7: \begin{̲e̲q̲u̲a̲t̲i̲o̲n̲*̲}̲
\begin{aligned…">\begin{equation*} \begin{aligned} L(\theta)-L\left(\theta^{(i)}\right) &amp;=\log \left(\sum_{Z} P(Y \mid Z, \theta) P(Z \mid \theta)\right)-\log P\left(Y \mid \theta^{(i)}\right)\\&amp;=\log \left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right)}\right)-\log P\left(Y \mid \theta^{(i)}\right) \\ &amp; \geqslant \sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right)}-\log P\left(Y \mid \theta^{(i)}\right) \\ &amp;=\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)} \end{aligned} \end{equation*}</p><p>欲求使得似然函数增加的参数估计值，需要将上述放缩后的函数最大化，抛去无关常数，则问题转化为：</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: equation* at position 7: \begin{̲e̲q̲u̲a̲t̲i̲o̲n̲*̲}̲
\begin{aligned…">\begin{equation*} \begin{aligned} \theta^{(i+1)} &amp;=\arg \max _{\theta}\left(L\left(\theta^{(i)}\right)+\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}\right) \\ &amp;=\arg \max _{\theta}\left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log (P(Y \mid Z, \theta) P(Z \mid \theta))\right) \\ &amp;=\arg \max _{\theta}\left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log P(Y, Z \mid \theta)\right) \\ &amp;=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right) \end{aligned} \end{equation*}</p><p>EM算法就是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法，这里的Q其实就是求<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">logP(Y,Z|\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.01968em">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:.03588em">g</span><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:.02778em">θ</span><span class="mclose">)</span></span></span></span>的期望值（注意这里的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>是观测值，换言之相当于是在Y和模型参数给定的条件下最大化期望值）<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/0.png" alt="image.png"></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false">(</mo><mi>θ</mi><mo separator="true">,</mo><msup><mi>θ</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B(\theta,\theta^{(i)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.05017em">B</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.02778em">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>即我们求得的真实下界<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/1.png" alt="image.png"><br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/2.png" alt="image.png"></p><h2 id="算法收敛性">算法收敛性</h2><p>可以证明随着迭代次数的增加，似然函数的值会不断增大，这也意味着如果似然函数有界，那么一定存在局部最优解或者全局最优解。本身是局部最优的算法，</p><h1 id="坐标上升法-coordinate-ascent">坐标上升法（Coordinate ascent）</h1><p>坐标上升法是一种与梯度下降法类似的方法，与梯度下降法不同之处在于梯度下降法目的是最小化代价函数，坐标上升法的目的是最大化似然函数；</p><p>梯度下降法每一步只更新模型参数，而Em算法的每一步既更新模型参数又更新隐含参数：</p><p><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/image-20220710214242845.png" alt="image-20220710214242845"></p><p>需要注意的是EM算法每一步只会优化一种参数，因此我们看到的优化路径是一种阶梯类型的（E步固定模型参数优化隐变量，M步固定因变量优化模型参数）</p><h2 id="应用">应用</h2><p>本质上来说算法的应用首先是一种局部固定单点突破的思想。</p><blockquote><p>如果我们从算法思想的角度来思考EM算法，我们可以发现我们的算法里已知的是观察数据，未知的是隐含数据和模型参数，在E步，我们所做的事情是固定模型参数的值，优化隐含数据的分布，而在M步，我们所做的事情是固定隐含数据分布，优化模型参数的值。</p></blockquote><h3 id="高斯混合模型">高斯混合模型</h3><p><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/3.png" alt="image.png"></p><h3 id="支持向量机的smo算法">支持向量机的SMO算法</h3><h3 id="k-means">K-means</h3><h3 id="马尔科夫模型">马尔科夫模型</h3></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://kebuaaa.github.io">爱编程的小明</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://kebuaaa.github.io/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/">https://kebuaaa.github.io/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://kebuaaa.github.io" target="_blank">小明的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/EM%E7%AE%97%E6%B3%95/">EM算法</a><a class="post-meta__tags" href="/tags/%E4%BC%98%E5%8C%96/">优化</a></div><div class="post-share"><div class="social-share" data-image="/top_img/10019.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/Logistic%20Regression/" title="Logistic Regression"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10009.webp" onerror='onerror=null,src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Logistic Regression</div></div><div class="info-2"><div class="info-item-1">当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，应该使用逻辑回归。这里，Y的值为0或1，它可以用以下方程表示： \begin{equation*} \begin{aligned} odds &amp;= \frac{p}{1-p}\\ &amp;=\frac{probability\hspace{5pt} of\hspace{5pt} event\hspace{5pt} occurrence}{probability\hspace{5pt} of\hspace{5pt} not\hspace{5pt} event...</div></div></div></a><a class="pagination-related" href="/time%E6%A8%A1%E5%9D%97/" title="time模块"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10002.webp" onerror='onerror=null,src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">time模块</div></div><div class="info-2"><div class="info-item-1">这一模块常用的是计时器函数，其次是时间戳函数。 time.sleep(sec)：计时器函数，让工作暂停 time.time():返回当前时间的时间戳，计算自1970.1.1到现在的时间差（通常叫做纪元，是不同系统之间最简单的交换日期和时间的方法）。 time.ctime()：将纪元值转化为字符串（“Mon Feb 3 22:31:03 2014”) time.localtime():默认返回一个struct_time，也可将一个时间参数传入该函数返回出对应的struct_time time.mktime():把stuct_time转化为纪元值（struct_time只能精确到秒） time.strftime(format, [t])： 把一个struct_time转换成格式化的时间字符串。格式由传入的format确定。支持的符号表如下： import...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/SVM%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/" title="对偶问题（SVM）"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10050.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-04</div><div class="info-item-2">对偶问题（SVM）</div></div><div class="info-2"><div class="info-item-1">Duality (optimization) In mathematical optimization theory, duality or the duality principle is the principle that optimization problems may be viewed from either of two perspectives, the primal problem or the dual problem. The solution to the dual problem provides a lower bound to the solution of the primal (minimization) problem.However in general the optimal values of the primal and dual problems need not be equal. Their difference is called the duality gap. For convex optimization...</div></div></div></a><a class="pagination-related" href="/Entropy/" title="Entroy"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10048.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-05</div><div class="info-item-2">Entroy</div></div><div class="info-2"><div class="info-item-1">点击查看【bilibili】 1 章 绪论.pdf 2 章 离散信源及其信息测度.pdf intro 熵可以从随机变量状态需要的平均信息量角度理解, 也可以从描述统计力学中无序程度的度量角度理解。从平均信息量的角度来看，对于不确定性事件，可以用消除其不确定性需要的信息量(bit 数)来表示，这里表示成−log⁡pi-\log p_i−logpi​,而考虑到随机事件的不确定性，可以通过对信息量求期望得到某随机事件（随机变量）的信息熵，信息熵越大，则说明（消除随机性）需要的信息量越大，即不确定性越大。 一般来说，对于随机变量XXX，其信息熵定义如下: H(X)=−∑i=1np(xi)log⁡2p(xi)H(X)=-\sum\limits_{i=1}^{n}p(x_i)\log_2{p(x_i)} H(X)=−i=1∑n​p(xi​)log2​p(xi​) if p=0p=0p=0，then...</div></div></div></a><a class="pagination-related" href="/Logistic%20Regression/" title="Logistic Regression"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10009.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-17</div><div class="info-item-2">Logistic Regression</div></div><div class="info-2"><div class="info-item-1">当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，应该使用逻辑回归。这里，Y的值为0或1，它可以用以下方程表示： \begin{equation*} \begin{aligned} odds &amp;= \frac{p}{1-p}\\ &amp;=\frac{probability\hspace{5pt} of\hspace{5pt} event\hspace{5pt} occurrence}{probability\hspace{5pt} of\hspace{5pt} not\hspace{5pt} event...</div></div></div></a><a class="pagination-related" href="/%E5%86%B3%E7%AD%96%E6%A0%91/" title="决策树模型"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10030.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-12</div><div class="info-item-2">决策树模型</div></div><div class="info-2"><div class="info-item-1">人们的决策过程是一个类似“观察因素A的情况，再根据A的情况观察因素B的情况”的形式，从而形成一种树状结构。决策树学习是模仿人类这一结构化决策过程而发展起来的一种有监督机器学习方法。 它可以被认为是if-then规则的集合，也可以被认为是定义在特征空间和类空间上的条件概率分布。 模型具有可读性 分类速度快 决策树的思想主要来源于Quinlan在1986年提出的ID3和1993提出的C4.5算法，以及由Breiman等人1984年提出的CART算法。 模型 决策树学习本质上是从训练数据集中归纳出一组分类规则或者条件概率模型（在节点处取条件概率最大的进行分类）。决策树问题一般可以分成特征选择、决策树生成、剪枝三部分。 特征选择：通过建立一个函数来衡量特征划分的效果 生成：递归构造决策树的过程 剪枝：递归产生的决策树往往会递归到不能分类为止，这会导致出现过拟合现象，因此需要已经生成的决策树进行剪枝(pruning)，一般是通过极小化决策树整体的损失函数(loss function)或者代价函数(cost...</div></div></div></a><a class="pagination-related" href="/%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95/" title="分类方法"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10017.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-06</div><div class="info-item-2">分类方法</div></div><div class="info-2"><div class="info-item-1">线性分类方法 感知机和线性判别分析/Fisher分析是非常经典的硬分类线性模型，模型提出都比较早。 感知机 感知机是二类分类的线性分类模型。 感知机只在求出线性可分的分类超平面，通过梯度下降法对损失函数极小化建立感知机模型。 感知机1957年由Rosenblatt提出，是神经网络和支持向量机的基础 模型 输入空间是实例向量组成的空间，输出空间是-1和+1（正负两类）。建立如下函数： \begin{align*} f(x)&amp;=sign(\omega \cdot x+b)\\ \omega&amp;:weight\quad or\quad weight\quad...</div></div></div></a><a class="pagination-related" href="/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" title="回归分析"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10026.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-09</div><div class="info-item-2">回归分析</div></div><div class="info-2"><div class="info-item-1">在实际中，常常希望根据已有数据，确定因变量（数值变量）与自变量(可以是类别变量)的关系,在此关系的基础上对未知数据进行预测。这种方法叫回归分析。 一般情况下可以按照模型的形式分为线性回归和非线性回归两种形式。 分类 线性模型 线性回归是在研究相关关系时优先考虑(最为直观)的一种模型，它假定所有解释变量对被解释变量的影响是线性叠加的，一般假设总体存在如下关系(矩阵形式): \begin{equation} \boldsymbol{Y}=\boldsymbol{X}...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">爱编程的小明</div><div class="author-info-description">只要不折腾，万般可将就</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kebuAAA"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/kebuAAA" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/2945190789@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/img/wechat.webp" target="_blank" title="欢迎交流"><i class="fa-brands fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">如网页加载较慢请尝试魔法上网，博客图文可能无关可以忽略</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#em%E7%AE%97%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">EM算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%AF%BC%E5%87%BA"><span class="toc-number">1.1.</span> <span class="toc-text">算法导出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%94%B6%E6%95%9B%E6%80%A7"><span class="toc-number">1.2.</span> <span class="toc-text">算法收敛性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9D%90%E6%A0%87%E4%B8%8A%E5%8D%87%E6%B3%95-coordinate-ascent"><span class="toc-number">2.</span> <span class="toc-text">坐标上升法（Coordinate ascent）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">2.1.</span> <span class="toc-text">应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.1.</span> <span class="toc-text">高斯混合模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84smo%E7%AE%97%E6%B3%95"><span class="toc-number">2.1.2.</span> <span class="toc-text">支持向量机的SMO算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means"><span class="toc-number">2.1.3.</span> <span class="toc-text">K-means</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.4.</span> <span class="toc-text">马尔科夫模型</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10042.webp" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="Lasso回归"></a><div class="content"><a class="title" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归">Lasso回归</a><time datetime="2023-11-14T16:00:00.000Z" title="更新于 2023-11-15 00:00:00">2023-11-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/岭回归_20231109082818.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="岭回归"></a><div class="content"><a class="title" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归">岭回归</a><time datetime="2023-11-07T16:00:00.000Z" title="更新于 2023-11-08 00:00:00">2023-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/优雅论文排版_20230921093206.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="优雅论文排版"></a><div class="content"><a class="title" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版">优雅论文排版</a><time datetime="2023-09-20T16:00:00.000Z" title="更新于 2023-09-21 00:00:00">2023-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/多元统计分析_多元正态曲线.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="多元统计分析"></a><div class="content"><a class="title" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析">多元统计分析</a><time datetime="2023-06-16T02:22:54.000Z" title="更新于 2023-06-16 10:22:54">2023-06-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Hypothesis%20testing/" title="假设检验"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10032.webp" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="假设检验"></a><div class="content"><a class="title" href="/Hypothesis%20testing/" title="假设检验">假设检验</a><time datetime="2023-05-09T02:34:00.000Z" title="更新于 2023-05-09 10:34:00">2023-05-09</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"></div><script src="/Scripts/js/beijing.js"></script><script src="/Scripts/js/foot_style.js"></script><script src="/Scripts/js/fireworks.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"])',selectors:["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"],cacheBust:!1,analytics:!1,scrollRestoration:!1});const e=e=>{e&&Object.values(e).forEach((e=>e()))};document.addEventListener("pjax:send",(()=>{btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");const t=document.body.classList;t.contains("read-mode")&&t.remove("read-mode"),e(window.globalFn.pjaxSend)})),document.addEventListener("pjax:complete",(()=>{btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach((e=>{const t=document.createElement("script"),n=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach((e=>t.setAttribute(e.name,e.value))),t.appendChild(document.createTextNode(n)),e.parentNode.replaceChild(t,e)})),e(window.globalFn.pjaxComplete)})),document.addEventListener("pjax:error",(e=>{404===e.request.status&&pjax.loadUrl("/404.html")}))})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","2s"),arr[i].setAttribute("data-wow-delay","0.5s"),arr[i].setAttribute("data-wow-offset","100"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow_init.js"></script></body></html>