<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>爬虫注意 | 小明的博客</title><meta name="author" content="爱编程的小明"><meta name="copyright" content="爱编程的小明"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#e68ab8"><meta name="description" content="..."><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kebuaaa.github.io/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E6%95%99%E7%A8%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//www.clarity.ms"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach((([e,t])=>n.setAttribute(e,t))),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),getCSS:(e,t)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),addGlobalFn:(e,t,o=!1,a=window)=>{const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#e68ab8")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>var _hmt=_hmt||[];!function(){var t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4e3a07c287f8fb6cfc09bf5a7fdc1dd7";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(t,a)}(),btf.addGlobalFn("pjaxComplete",(()=>{_hmt.push(["_trackPageview",window.location.pathname])}),"baidu_analytics")</script><script>!function(e,t,n,c,a,i,r){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(i=t.createElement(c)).async=1,i.src="https://www.clarity.ms/tag/e8bjif1knd",(r=t.getElementsByTagName(c)[0]).parentNode.insertBefore(i,r)}(window,document,"clarity","script")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:{defaultEncoding:1,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!1},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"爬虫注意",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,isShuoshuo:!1}</script><style>#article-container.post-content h1:before,h2:before,h3:before,h4:before,h5:before,h6:before{-webkit-animation:avatar_turn_around 1s linear infinite;-moz-animation:avatar_turn_around 1s linear infinite;-o-animation:avatar_turn_around 1s linear infinite;-ms-animation:avatar_turn_around 1s linear infinite;animation:avatar_turn_around 1s linear infinite}</style><link rel="stylesheet" href="/Scripts/css/transparent.css"><link rel="stylesheet" href="/Scripts/css/font.css"><link rel="stylesheet" href="/Scripts/css/foot_style.css"><link rel="stylesheet" href="/Scripts/css/twikoo_beautify.css"><link rel="stylesheet" href="/Scripts/css/tags.css"><link rel="stylesheet" href="/Scripts/css/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/animate.css/4.1.1/animate.min.css" media="print" onload='this.media="screen"'><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet"></head><body><div id="web_bg" style="background-image:url(url(/img/index_img.webp))"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i> <span>壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i> <span>开往</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">小明的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">爬虫注意</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i> <span>壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i> <span>开往</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">爬虫注意<a class="post-edit-link" href="https://github.dev/kebuAAA/myblog/blob/main/source/_posts/网页抓取教程.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-05T02:03:00.000Z" title="发表于 2022-03-05 10:03:00">2022-03-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-06T02:03:00.000Z" title="更新于 2022-03-06 10:03:00">2022-03-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%88%AC%E8%99%AB/%E7%90%86%E8%AE%BA/">理论</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>大多数浏览器都支持对网页的审查，在对我们提取的数据的位置进行定位时往往需要借助网页的开发者工具。鼠标右键选择对网页“检查”即可打开该功能</p><h1 id="检查浏览器dom时的注意事项">检查浏览器DOM时的注意事项</h1><p>当我们查看网页的DOM时，我们看到的并不是原本的html文件，而是浏览器清理和执行过Java代码的网页。例如火狐会给网页中的表格元素添加</p><tbody>元素，但如果这样的东西出现在我们的xpath语句中，则不能提取出任何东西。<p></p><ul><li>在对网页审查在开发者模式下禁用JavaScript（或者可以右键查看页面源代码）</li><li>不要使用包含全部路径的Xpath的语句（避免包含/tbody）使用相对路径或者比较大的搜索语句</li></ul><h1 id="动态网页抓取">动态网页抓取</h1><p>在抓取网页时，有的页面是经过几次连续的请求才抓取成功的，这个时候我们可以借助检查工具中的“网络”来对网页加载的请求进行一个查看。拿<a target="_blank" rel="noopener" href="https://quotes.toscrape.com/scroll">https://quotes.toscrape.com/scroll</a>网站举一个例子，打开该网站发现，该网站的页面加载功能是当我们将页面滚动到最下面之后自动加载出来的。这个时候就需要用到Net-work Tool了。打开对应的网页：<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E6%95%99%E7%A8%8B/0.png" alt="image.png"><br>注意选定保留日志选项，防止日志被自动清楚。打开该窗口我们选择打开一个文件后可以查看我们请求网页时的信息（浏览器表示，Ip地址之类）。通过观察我们发现我们需要用到的是quotes?page=1文件，该文件是json格式，通过该文件我们 能找到我们需要爬取的数据。进而我们可以设置自己的爬虫规则：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuoteSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;quote&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;quotes.toscrape.com&#x27;</span>]</span><br><span class="line">    page = <span class="number">1</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://quotes.toscrape.com/api/quotes?page=1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        data = json.loads(response.text)</span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> data[<span class="string">&quot;quotes&quot;</span>]:</span><br><span class="line">            <span class="keyword">yield</span> &#123;<span class="string">&quot;quote&quot;</span>: quote[<span class="string">&quot;text&quot;</span>]&#125;</span><br><span class="line">        <span class="keyword">if</span> data[<span class="string">&quot;has_next&quot;</span>]:</span><br><span class="line">            self.page += <span class="number">1</span></span><br><span class="line">            url = <span class="string">f&quot;https://quotes.toscrape.com/api/quotes?page=<span class="subst">&#123;self.page&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br></pre></td></tr></table></figure><h2 id="添加headers和cooikes">添加headers和cooikes</h2><p>当网页比较复杂时，我们可能需要对网页进行伪装来实现对网页的爬取。首先我们可以借助浏览器的检查工具将请求导出为cURL格式，然后通过Request库中的<code>from_curl()</code>来实现一个正常的请求：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line">request = Request.from_curl(</span><br><span class="line">    <span class="string">&quot;curl &#x27;https://quotes.toscrape.com/api/quotes?page=1&#x27; -H &#x27;User-Agent: Mozil&quot;</span></span><br><span class="line">    <span class="string">&quot;la/5.0 (X11; Linux x86_64; rv:67.0) Gecko/20100101 Firefox/67.0&#x27; -H &#x27;Acce&quot;</span></span><br><span class="line">    <span class="string">&quot;pt: */*&#x27; -H &#x27;Accept-Language: ca,en-US;q=0.7,en;q=0.3&#x27; --compressed -H &#x27;X&quot;</span></span><br><span class="line">    <span class="string">&quot;-Requested-With: XMLHttpRequest&#x27; -H &#x27;Proxy-Authorization: Basic QFRLLTAzM&quot;</span></span><br><span class="line">    <span class="string">&quot;zEwZTAxLTk5MWUtNDFiNC1iZWRmLTJjNGI4M2ZiNDBmNDpAVEstMDMzMTBlMDEtOTkxZS00MW&quot;</span></span><br><span class="line">    <span class="string">&quot;I0LWJlZGYtMmM0YjgzZmI0MGY0&#x27; -H &#x27;Connection: keep-alive&#x27; -H &#x27;Referer: http&quot;</span></span><br><span class="line">    <span class="string">&quot;://quotes.toscrape.com/scroll&#x27; -H &#x27;Cache-Control: max-age=0&#x27;&quot;</span>)</span><br></pre></td></tr></table></figure><p>curl导出为scrapy request可以直接借助网站（导出为bash格式再转换）：<br>另外如果需要知道上述类方法的输入参数，可以通过<code>curl_to_request_kwargs()</code> 方法查询：<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E6%95%99%E7%A8%8B/1.png" alt="image.png"></p></tbody></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://kebuaaa.github.io">爱编程的小明</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://kebuaaa.github.io/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E6%95%99%E7%A8%8B/">https://kebuaaa.github.io/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E6%95%99%E7%A8%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://kebuaaa.github.io" target="_blank">小明的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python%E7%88%AC%E8%99%AB/">Python爬虫</a></div><div class="post-share"><div class="social-share" data-image="/top_img/10030.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10030.webp" onerror='onerror=null,src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">神经网络</div></div><div class="info-2"><div class="info-item-1">神经网络 scikit-learn提供了MLPClassifier()和MLPRegression()两个类，分别用于神经网络分类和回归任务。 多层感知器(MLP) 的监督学习算法，通过在数据集特征 X = {x1, x2, …, xm} 和标签y上训练来学习函数：MLPClassifier()： class sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100, ), activation=&#x27;relu&#x27;, solver=&#x27;adam&#x27;, alpha=0.0001, batch_size=&#x27;auto&#x27;, learning_rate=&#x27;constant&#x27;, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False,...</div></div></div></a><a class="pagination-related" href="/%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95/" title="分类方法"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10029.webp" onerror='onerror=null,src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">分类方法</div></div><div class="info-2"><div class="info-item-1">线性分类方法 感知机和线性判别分析/Fisher分析是非常经典的硬分类线性模型，模型提出都比较早。 感知机 感知机是二类分类的线性分类模型。 感知机只在求出线性可分的分类超平面，通过梯度下降法对损失函数极小化建立感知机模型。 感知机1957年由Rosenblatt提出，是神经网络和支持向量机的基础 模型 输入空间是实例向量组成的空间，输出空间是-1和+1（正负两类）。建立如下函数： \begin{align*} f(x)&amp;=sign(\omega \cdot x+b)\\ \omega&amp;:weight\quad or\quad weight\quad...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/Scrapy%E6%A1%86%E6%9E%B6/" title="Scrapy框架"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10031.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-01</div><div class="info-item-2">Scrapy框架</div></div><div class="info-2"><div class="info-item-1">Scrapy确实是提高爬虫效率很好的一个方法，但框架式的内容也对自身对爬虫技能的掌握程度提出了一个全新的要求，目前自身的爬虫技能仍有待进一步加强，相信以后会越做越好。 简单网页的爬取可以利用re模块，复杂网页的爬取对于内容的提取则会显得十分麻烦。Scrapy框架是python下的一个爬虫框架，因为它足够简单方便受到人们的青睐。 选择器（提取数据的机制） Scrapy提取数据有自己的一套机制。 它们被称作选择器（seletors)，通过特定的XPath或者CSS表达式来“选择”HTML文件中的某个部分。XPath是一门用来在XML文件中选择节点的语言， 也可以用在HTML上。 CSS是一门将HTML文档样式化的语言。 选择器由它定义，并与特定的HTML元素的样式相关联。 Scrapy的选择器构建于lxml库之上， 这意味着它们在速度和解析准确性上非常相似， 所以看你喜欢哪种选择器就使用哪种吧， 它们从效率上看完全没有区别。 XPath选择器 XPath是一门在XML文档中查找信息的语言。 如果实在不想自己写的话可以借助edge浏览器的插件SelectorGadget...</div></div></div></a><a class="pagination-related" href="/Working%20with%20APIs/" title="Working with APIs"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10005.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-23</div><div class="info-item-2">Working with APIs</div></div><div class="info-2"><div class="info-item-1">An API is a collection of tools that allows different applications to interact. 与我们获取网页相似，我们对API发出请求数据的请求，然后服务器作出相应，返回我们请求的数据。这一过程在python中主要通过requests库实现 发起请求： get() post():post请求一般会包含数据，因为这个请求本身就是用来发送给服务器请求服务器创建一个object用的 post请求成功会返回一个201的状态码 For example, we use POST requests to send information (instead of retrieve it), and to create objects on the API’s server. With the GitHub API, we can use POST requests to create new repositories. Different API endpoints choose what types of...</div></div></div></a><a class="pagination-related" href="/html/" title="html"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/html_20230406215949.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-24</div><div class="info-item-2">html</div></div><div class="info-2"><div class="info-item-1">简介 HTML 是用来描述网页的一种语言。 HTML 指的是超文本标记语言 (Hyper Text Markup Language) HTML 不是一种编程语言，而是一种标记语言 (markup language) 标记语言是一套标记标签 (markup tag) HTML 使用标记标签来描述网页 HTML 标记标签通常被称为 HTML 标签 (HTML tag): HTML 标签是由尖括号包围的关键词，比如 &lt;html&gt; HTML 标签通常是成对出现的，比如 &lt;b&gt; 和 &lt;/b&gt; 标签对中的第一个标签是开始标签，第二个标签是结束标签 开始和结束标签也被称为开放标签和闭合标签 html文档包括html标签和纯文本，html文档也被称为网页。Web浏览器的作用是读取HTML文档，并以网页的形式显示出来。 常用的html标签 一个html文档大概会包括以下内容，复杂网页一般会包括更多不同的标签以及对标签进行属性的调整来得到更加丰富的页面。 &lt;html&gt; &lt;body&gt; &lt;h1&gt;My First...</div></div></div></a><a class="pagination-related" href="/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/" title="爬虫入门"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10045.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-27</div><div class="info-item-2">爬虫入门</div></div><div class="info-2"><div class="info-item-1">python爬虫书目推荐.xmind 基本内容 爬虫通俗来说就是一个模拟人类请求网站行为的程序。可以自动请求网页、并把数据抓取下来，然后使用一定的规则则提取有价值的数据。也可以理解为使用某种编程语言（这里当然是使用Python语言） 按照一定的顺序、 规则主动抓取互联网特定信息的程序或者脚本。 爬虫可以分为通用爬虫和聚焦爬虫 各大搜索引擎是通用爬虫一个很好的例子，通用爬虫在爬取内容时并不会对网页内容进行筛选，将网页的全部内容给爬取下来。 聚焦爬虫则是只爬取网页上自己需要的内容。 使用语言： php:多线程异步处理能力弱 C/C++:学习成本高，运行速度快但学习和开发成本高 Java:生态圈完善，python爬虫的最大竞争对手。但Java语言本身笨重，代码量大。重构成本搞（有的网站会更新网页编码的规则，需要不断重构来匹配规则） python:语法优美，代码简洁，开发效率高。相关的HTTP请求模块和HTML解析模块非常丰富。还有Scrapy和Scrapy-redis框架让我们开发爬虫变得异常简单。 http协议 HTTP协议：全称是HyperText Transfer...</div></div></div></a><a class="pagination-related" href="/%E7%BA%BF%E7%A8%8B&%E8%BF%9B%E7%A8%8B/" title="线程&amp;进程"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10047.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-08</div><div class="info-item-2">线程&amp;进程</div></div><div class="info-2"><div class="info-item-1">线程和进程是计算机任务处理中的两个概念，一个进程相当于计算机处理的一个任务，一个任务可以找通过多种方式或者找多个不同的人去执行，每一个人或者每一种方式就是一种线程。 多进程问题涉及的是任务的分工问题，一般来说是将一个复杂的任务拆分成多个子任务，每一个子任务执行的时候其它子任务也可以同时执行,例如分布式计算。这种分工的好处是可以保证资源的充分利用，但是如果父任务的执行出现错误或者计算错误，那么后边的任务也会受到影响。多进程问题的优化主要是一个多任务管理的方式问题，一般常用的一种方法是队列。 多线程问题主要涉及到的是协作问题，通过建立多个可以独立完成任务的线程来完成任务，很明显的一个优势是运行的效率会比较高。但是当线程之间如果使用同样的变量时则会存在并发的风险，这会大大降低多线程工作的效率，一般来说多线程的优化问题主要是如何减少线程之间的相互影响，一种比较有效的方式就是加一层锁，限制做个线程同时对一个变量进行更改的权利 在 Python 中，线程不能加速受 CPU 限制的任务，原因是标准 Python 系统中使用了全局解释器锁（GIL）。 GIL 的作用是避免 Python...</div></div></div></a><a class="pagination-related" href="/%E7%BD%91%E9%A1%B5%E4%B8%8B%E8%BD%BD/" title="网页下载"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10025.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-19</div><div class="info-item-2">网页下载</div></div><div class="info-2"><div class="info-item-1">爬虫的第一步是向网页发起模拟请求，一般来说模拟请求的可以借助Python中的urllib模块以及requests模块，其中requests模块是对urllib模块的一个封装，从实用性的角度出发，一般来说我们更建议使用requests模块 request.get发起网页请求 requests库调用是requests.get方法传入url和参数，返回的对象是Response对象，打印出来是显示响应状态码。 Response对象比较重要的三个属性: text:unicode 型的数据，一般是在网页的header中定义的编码形式， content返回的是bytes，二进制型的数据。 json也可以返回json字符串。 如果想要提取文本就用text，但是如果你想要提取图片、文件等二进制文件，就要用content，当然decode之后，中文字符也会正常显示。 修改头文件(Headers) pcUserAgent = &#123;&quot;safari 5.1 – MAC&quot;:&quot;User-Agent:Mozilla/5.0 (Macintosh; U; Intel...</div></div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">爱编程的小明</div><div class="author-info-description">只要不折腾，万般可将就</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kebuAAA"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/kebuAAA" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/2945190789@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/img/wechat.webp" target="_blank" title="欢迎交流"><i class="fa-brands fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">如网页加载较慢请尝试魔法上网，博客图文可能无关可以忽略</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E6%B5%8F%E8%A7%88%E5%99%A8dom%E6%97%B6%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.</span> <span class="toc-text">检查浏览器DOM时的注意事项</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96"><span class="toc-number">2.</span> <span class="toc-text">动态网页抓取</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0headers%E5%92%8Ccooikes"><span class="toc-number">2.1.</span> <span class="toc-text">添加headers和cooikes</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10029.webp" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="Lasso回归"></a><div class="content"><a class="title" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归">Lasso回归</a><time datetime="2023-11-14T16:00:00.000Z" title="更新于 2023-11-15 00:00:00">2023-11-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/岭回归_20231109082818.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="岭回归"></a><div class="content"><a class="title" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归">岭回归</a><time datetime="2023-11-07T16:00:00.000Z" title="更新于 2023-11-08 00:00:00">2023-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/优雅论文排版_20230921093206.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="优雅论文排版"></a><div class="content"><a class="title" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版">优雅论文排版</a><time datetime="2023-09-20T16:00:00.000Z" title="更新于 2023-09-21 00:00:00">2023-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/多元统计分析_多元正态曲线.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="多元统计分析"></a><div class="content"><a class="title" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析">多元统计分析</a><time datetime="2023-06-16T02:22:54.000Z" title="更新于 2023-06-16 10:22:54">2023-06-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Hypothesis%20testing/" title="假设检验"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10036.webp" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="假设检验"></a><div class="content"><a class="title" href="/Hypothesis%20testing/" title="假设检验">假设检验</a><time datetime="2023-05-09T02:34:00.000Z" title="更新于 2023-05-09 10:34:00">2023-05-09</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(()=>{const o=GLOBAL_CONFIG_SITE.isShuoshuo,t=null,e=(e=document,n=location.pathname)=>{twikoo.init({el:e.querySelector("#twikoo-wrap"),envId:"https://twikoo.kobal.top/",region:"",onCommentLoaded:()=>{btf.loadLightbox(document.querySelectorAll("#twikoo .tk-content img:not(.tk-owo-emotion)"))},...t,path:n}),o&&(window.shuoshuoComment.destroyTwikoo=()=>{e.children.length&&(e.innerHTML="",e.classList.add("no-comment"))})},n=(o,t)=>{"object"==typeof twikoo?setTimeout((()=>e(o,t)),0):btf.getScript("https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js").then((()=>e(o,t)))};o?window.shuoshuoComment={loadComment:n}:btf.loadComment(document.getElementById("twikoo-wrap"),n)})()</script></div><script src="/Scripts/js/beijing.js"></script><script src="/Scripts/js/foot_style.js"></script><script src="/Scripts/js/fireworks.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"])',selectors:["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"],cacheBust:!1,analytics:!1,scrollRestoration:!1});const e=e=>{e&&Object.values(e).forEach((e=>e()))};document.addEventListener("pjax:send",(()=>{btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");const t=document.body.classList;t.contains("read-mode")&&t.remove("read-mode"),e(window.globalFn.pjaxSend)})),document.addEventListener("pjax:complete",(()=>{btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach((e=>{const t=document.createElement("script"),n=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach((e=>t.setAttribute(e.name,e.value))),t.appendChild(document.createTextNode(n)),e.parentNode.replaceChild(t,e)})),e(window.globalFn.pjaxComplete)})),document.addEventListener("pjax:error",(e=>{404===e.request.status&&pjax.loadUrl("/404.html")}))})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","2s"),arr[i].setAttribute("data-wow-delay","0.5s"),arr[i].setAttribute("data-wow-offset","100"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/wow/1.1.2/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script></body></html>