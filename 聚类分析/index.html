<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>聚类分析 | 小明的博客</title><meta name="author" content="爱编程的小明"><meta name="copyright" content="爱编程的小明"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#e68ab8"><meta name="description" content="..."><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "聚类分析",
  "url": "https://kebuaaa.github.io/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/",
  "image": "https://kebuaaa.github.io/top_img/10054.webp",
  "datePublished": "2022-02-04T05:02:00.000Z",
  "dateModified": "2022-08-29T05:02:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "爱编程的小明",
      "url": "https://kebuaaa.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kebuaaa.github.io/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//www.clarity.ms"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach((([e,t])=>n.setAttribute(e,t))),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),getCSS:(e,t)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),addGlobalFn:(e,t,o=!1,a=window)=>{const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#e68ab8")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>var _hmt=_hmt||[];!function(){var t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4e3a07c287f8fb6cfc09bf5a7fdc1dd7";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(t,a)}(),btf.addGlobalFn("pjaxComplete",(()=>{_hmt.push(["_trackPageview",window.location.pathname])}),"baidu_analytics")</script><script>!function(e,t,n,c,a,i,r){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(i=t.createElement(c)).async=1,i.src="https://www.clarity.ms/tag/e8bjif1knd",(r=t.getElementsByTagName(c)[0]).parentNode.insertBefore(i,r)}(window,document,"clarity","script")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:{defaultEncoding:1,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!1},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyloadPlugin:!0,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"聚类分析",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><style>#article-container.post-content h1:before,h2:before,h3:before,h4:before,h5:before,h6:before{-webkit-animation:avatar_turn_around 1s linear infinite;-moz-animation:avatar_turn_around 1s linear infinite;-o-animation:avatar_turn_around 1s linear infinite;-ms-animation:avatar_turn_around 1s linear infinite;animation:avatar_turn_around 1s linear infinite}</style><link rel="stylesheet" href="/Scripts/css/transparent.css"><link rel="stylesheet" href="/Scripts/css/font.css"><link rel="stylesheet" href="/Scripts/css/foot_style.css"><link rel="stylesheet" href="/Scripts/css/twikoo_beautify.css"><link rel="stylesheet" href="/Scripts/css/tags.css"><link rel="stylesheet" href="/Scripts/css/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet"></head><body><div id="web_bg" style="background-image:url(url(/img/index_img.webp))"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i> <span>壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i> <span>开往</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">小明的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">聚类分析</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>存档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div><div class="menus_item"><a class="site-page" href="/wallpaper/"><i class="fa-fw fas fa-image fa-fw"></i> <span>壁纸</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i> <span>开往</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">聚类分析<a class="post-edit-link" href="https://github.dev/kebuAAA/myblog/blob/main/source/_posts/聚类分析.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-04T05:02:00.000Z" title="发表于 2022-02-04 13:02:00">2022-02-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-29T05:02:00.000Z" title="更新于 2022-08-29 13:02:00">2022-08-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/">模型</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>聚类是一种无监督学习，聚类的方法几乎可以应用于所有对象。<br>聚类分析根据聚类算法将数据或样本对象划分成两个以上的子集。<br>每一个子集称为一个簇，簇中对象因特征属性值接近而彼此相似。不同簇对象之间则彼此存在差异。<br>把相似的对象归于统一组，不同对象归于不同组。需要一种<strong>相似度的计算方法</strong></p><h1 id="相似度的计算方法">相似度的计算方法</h1><ul><li>Manhattan Distance（曼哈顿距离）（l1范数）</li><li>Euclidean Distance（欧式距离），距离测度中简单直观的适合于二、三维的距离测度（l2范数）：</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">d=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.1568160000000005em;vertical-align:-1.277669em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000006em"><span class="svg-align" style="top:-5.116816em"><span class="pstrut" style="height:5.116816em"></span><span class="mord" style="padding-left:1.056em"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em"><span class="pstrut" style="height:5.116816em"></span><span class="hide-tail" style="min-width:.742em;height:3.196816em"><svg width="400em" height="3.196816em" viewBox="0 0 400000 3196" preserveAspectRatio="xMinYMin slice"><path d="M702 80H40000040 742v3062l-4 4-4 4c-.667.7-2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667-294.333-240-727l-212-643-85 170c-4-3.333-8.333-7.667-13-13l-13-13 77-155 77-156c66 199.333 139 419.667 219 661l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span></span></span></span></span></p><ul><li>Minkowski Distance（闵可夫斯基距离），可以理解为n维空间的欧式距离：</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>=</mo><mroot><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mi>q</mi></msup></mrow><mi>q</mi></mroot></mrow><annotation encoding="application/x-tex">d=\sqrt[q]{\sum_{i=1}^n(x_i-y_i)^q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.1568160000000005em;vertical-align:-1.277669em"></span><span class="mord sqrt"><span class="root"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5761668000000003em"><span style="top:-2.8608868000000003em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size6 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03588em">q</span></span></span></span></span></span></span></span><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000006em"><span class="svg-align" style="top:-5.116816em"><span class="pstrut" style="height:5.116816em"></span><span class="mord" style="padding-left:1.056em"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.590392em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:.03588em">q</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em"><span class="pstrut" style="height:5.116816em"></span><span class="hide-tail" style="min-width:.742em;height:3.196816em"><svg width="400em" height="3.196816em" viewBox="0 0 400000 3196" preserveAspectRatio="xMinYMin slice"><path d="M702 80H40000040 742v3062l-4 4-4 4c-.667.7-2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667-294.333-240-727l-212-643-85 170c-4-3.333-8.333-7.667-13-13l-13-13 77-155 77-156c66 199.333 139 419.667 219 661l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span></span></span></span></span></p><ul><li>Cosine Distance（余弦距离）（n维向量夹角）</li><li>Mahalanobis Distance马氏距离<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/0.png" alt="image.png"></li></ul><h1 id="聚类分析方法">聚类分析方法</h1><p><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/1658589271425.png" alt="1658589271425"></p><h2 id="划分法-partitioning-method">划分法(Partitioning Method)</h2><p>将N个对象划分为k组。<br>基于距离采取互斥的簇划分，采用迭代的定位技术，将一个对象从一个簇移至另一个簇来改进划分，使得簇内对象尽量相关，簇间对象尽可能无关。<br>K-means 是典型的基于划分的聚类算法</p><h2 id="层次法-hierarchical-method">层次法(Hierarchical Method)</h2><p>对数据对象集进行层次分解。</p><ul><li>凝聚法，将每一个对象作为一个单独簇，自底向上逐次合并相近的簇</li><li>分裂法，自顶向下分裂簇以得到满足要求的簇</li></ul><h2 id="基于密度的方法-density-based-method">基于密度的方法(Density-based Method)</h2><p>大部分划分法是基于距离进行聚类，因此只能发现球状簇，对非球状簇的数据集不适用。<br>基于密度的方法则可以用于<strong>非球状数据集</strong>的聚类。<br>主要思想：只要簇“邻域”中的密度到达了设定的阈值，就将其划分给该簇。<br>也就是说，簇中的每个中心点），在给定半径的邻域中至少都含有一定数目的数据点。<br>基于密度的方法可以<strong>过滤噪声</strong>或<strong>离群点</strong>，并发现任意形状的簇。</p><h2 id="基于网格的方法-grid-based-method">基于网格的方法(Grid-based Method)</h2><p>基于网格的方法是将对象空间分割成有限个单元形成网格结构，然后在网格结构上进行聚类操作。<br>该方法的处理速度很快，因为其执行时间通常独立于数据对象的个数，而仅仅由量化空间中每一维的单元数决定。</p><h1 id="聚类分析的过程">聚类分析的过程</h1><ul><li>样本准备与特征提取：根据样本特性选取有效特征，并将特征组向量化；</li><li>相似度计算：选择合适的距离测度函数，计算相似度</li><li>聚类：根据聚类算法进行聚类</li><li>聚类结果评估：对聚类质量进行评估并对结果进行解读。</li></ul><h2 id="聚类算法的模型评估指标">聚类算法的模型评估指标</h2><p>通过衡量簇内差异来衡量聚类的效果。</p><h3 id="不选择使用inertia进行评估的原因">不选择使用Inertia进行评估的原因</h3><ul><li>不存在统一的标准来界定Inertia作为判断标准</li><li>它的计算太容易受到特征数目的影响，数据维度很大的时候， Inertial的计算量会陷入维度诅咒之中，计算量会爆炸，不适合用来一次次评估模型。</li><li>对数据的分布有假设，假设数据满足凸分布（图像是凸函数），并假设数据是各向同性的（属性在不同方向代表相同含义）。这些使得它在细长簇、环形簇或者不规则流形时表现不佳。</li></ul><h3 id="当真实标签已知的时候">当真实标签已知的时候</h3><p><strong>外在方法</strong>是在有基准可用的条件下，通过比较聚类结果和基准来评估聚类质量；<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/1.png" alt="image.png"></p><h3 id="当真实标签未知的时候">当真实标签未知的时候</h3><p><strong>内在方法</strong>是在没有基准可用的情况下，通过<strong>簇间</strong>的分离情况和<strong>簇内</strong>的紧凑情况来评估聚类质量。</p><h4 id="轮廓系数-silhouette-coefficient">轮廓系数(Silhouette Coefficient)</h4><p>是内在评估方法常用的度量。假设N个样本组成的数据集分成了K个簇<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>3</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>C</mi><mi>K</mi></msub><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">C_1,C_2,C_3,\dots,C_K.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span>对于每个样本s<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">\in K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5782em;vertical-align:-.0391em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">K</span></span></span></span>,s与簇内其他对象之间的平均距离为:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: equation at position 7: \begin{̲e̲q̲u̲a̲t̲i̲o̲n̲}̲
a(s)=\frac{\su…">\begin{equation} a(s)=\frac{\sum_{s&#039;\in C_i,s\ne s&#039;}dist(s,s&#039;)}{|C_i|-1} \end{equation}</p><p>s与不属于所在簇的对象之间的最小平均距离为：</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: equation at position 7: \begin{̲e̲q̲u̲a̲t̲i̲o̲n̲}̲
b(s)=\min \lar…">\begin{equation} b(s)=\min \large{ \frac{\sum_{s&#039;\in C_j}dist(s,s&#039;)}{|C_j|-1} \large}(j=1,2,3,\dots,K且j\ne i) \end{equation}</p><p>样本s的轮廓系数定义为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>−</mo><mi>a</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>a</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">r(s)=\frac{b(s)-a(s)}{\max \{a(s),b(s)\}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.02778em">r</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">max</span><span class="mopen">{</span><span class="mord mathdefault">a</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mclose">}</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">a</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>b(s)衡量s与其他簇的分离程度。a(s)衡量s与所属簇的紧密性。，轮廓系数越接近1，聚类效果越好。<br>优缺点评价：</p><ul><li>优点：在有限空间取值；对数据分布没有假设，实用性强</li><li>缺点：在凸型的雷伤会比真实聚类得到更高的分数。</li></ul><p><strong>python实现</strong><br>在sklearn中，模块metrics中的类<code>silhouette_score</code>来计算轮廓系数，返回值为所有样本轮廓系数的均值，同时还有一个<code>silhouette_sample</code>，返回每个样本自己的轮廓系数。</p><h4 id="卡林斯基哈拉巴斯指数-calinski-harabaz-index">卡林斯基哈拉巴斯指数（Calinski-harabaz Index）</h4><h4 id="就维斯-布尔丁指数">就维斯-布尔丁指数</h4><h4 id="权变矩阵">权变矩阵</h4><h1 id="k-means聚类算法">K-means聚类算法</h1><p>K指分类为K簇，means意为簇的中心，即聚类中样本的均值。<br>算法思想：任选K个样本点作为中心，将剩余样本点进行划分。重新确定各个簇的中心，再将剩余点进行划分；不断重复这个过程，直至各个簇的质心不再变化。<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/2.png" alt="image.png"></p><h2 id="初始质心的选择">初始质心的选择</h2><p>K-Means算法中初始质心的放置是一个非常重要的环节，虽然时间足够的情况下一定会收敛，但是可能会收敛到局部最小值。<br>初始质心放置的位置不同，聚类的结果很可能也会不ー样，一个好的质心选择可以让K- Means避免更多的计算，让算法收敛稳定且更快。在之前讲解初始质心的放置时，我们是使用随机的方法在样本点中抽取k个样本作为初始质心，这种方法显然不符合稳定且更快的需求。为此，我们可以使用 random_ state参数来控制每次生成的初始质心都在相同位置，甚至可以画学习曲线来确定最优的 random_state是哪个整数<br>一个 random state对应一个质心随机初始化的随机数种子。如果不指定随机数种子，则 stearn中的K- means并不会只选择一个随机模式扔出结果，而会在每个随机数种子下运行多次，井使用结果最好的一个随机数种子来作为初始质心。我们可以使用参数n_init来选择，每个随机数种子下运行的次数。这个参数不常用到，默认10次，如果我们希望运行的结果更加精确，那我们可以増加这个参数n_ini的值来増加每个随机数种子下运行的次数。<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/3.png" alt="image.png"></p><h2 id="k值的选择依据">K值的选择依据</h2><p>K值选择需要建立一个距离测度指标，首先确定一个距离的计算方法，然后通过求簇内平方和（簇内所有样本点与质点差的平方和）来表示。例如采用欧几里得距离，则：<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/4.png" alt="image.png"><br>其中簇内平方和（cluster Sum of Square）又叫做Inertia。<br>肘部法则：首先确定一个用来评价聚合效果的函数（这里以Inertia为例子），以分类个数K为自变量，分类后的误差平方和SSE为因变量，则曲线的拐点即为最佳聚类簇数。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>a</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><munder><mo>∑</mo><mrow><msub><mi>x</mi><mi>j</mi></msub><mo>∈</mo><msub><mi>C</mi><mi>k</mi></msub></mrow></munder><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>−</mo><msub><mi>c</mi><mi>k</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">Inertia=\sum_{k=1}^K\sum _{x_j\in C_k}(x_j-c_k)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">I</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:.02778em">r</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.319992em;vertical-align:-1.491656em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8556639999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2818857142857143em"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:-.07153em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.491656em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>Inertia用来衡量聚合效果的好坏（也可以用其他方法来衡量样本到簇中心的距离指标）<br>K较小时，随着K的增大，分类更加精细，每个簇的聚合程度比较高，SSE下降较快。K超过最优聚类簇数时，Inertia的下降速度会骤减，Inertia会随着K值的继续增大而逐渐趋于平缓。SSE和K的关系图像人的手肘。</p><h1 id="knn">KNN</h1><p>输入实例最临近的k个实例中多数属于哪个类，该实例就属于哪个类。一种基本的分类和回归方法。<br>K近邻法中，当训练集、距离度量、k值及分类决策规则（如多数表决）确定后，对于任何一个新的输入实例，它所属的类唯一确定。</p><p>实例点与它的k个最临近点组成一个单元（cell)</p><h2 id="模型">模型</h2><h3 id="距离度量">距离度量</h3><p><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/5.png" alt="image.png"></p><h3 id="k值的选择">k值的选择</h3><p>k值的选择会对结果产生重大影响，一般通过交叉验证法来选取最优的k值。</p><h3 id="分类决策依据">分类决策依据</h3><p>往往采用多数表决规则。<br>多数表决也可以看成是以0-1损失函数的经验风险函数最小化的训练结果。</p><h2 id="具体实现算法-kd树">具体实现算法–kd树</h2><p>实现k近邻法时，主要考虑的问题是如何对训练数据进行快速k近邻搜索。这点在特征空间的维数大及训练数据容量大时尤其必要。<br>k近邻法最简单的实现方法是线性扫描(linear scan)。这时要计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，这种方法是不可行的。<br>为了提高飞近邻搜索的效率，可以考虑使用特殊的结构存储训练数据，以减少计算距离的次数。具体方法很多，下面介绍其中的kd树(kd tree)方法①。<br>kd树中的k是指数据的维度，与KNN中的k表示的是不同的含义<br>首先确定一个根节点，然后沿着一个坐标轴，用垂直于该坐标轴的超平面对区域进行切分（通常选择所有实例点在该坐标轴上的中位数为切分点，尽管这样得到的kd树搜索时的效率未必是最高的），落在切分超平面的点保存为根节点，然后对切分产生的子区域重复切分操作。<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/6.png" alt="image.png"></p><h3 id="搜索">搜索</h3><p>首先自上而下搜索确定距离输入点最近的树的叶节点，将此叶节点作为“当前最近点”，然后回退到上一节点，在上一节点的其他同级节点自上而下搜索是否存在比当前最近点更近的的点，如果存在，就更新当前最近点重新进行搜索。<br><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="../md_imgs/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/7.png" alt="image.png"><br>从搜索方法上看，如果实例点是随机分布的，搜索的平均计算法复杂度是logN，N是训练实例数。<br><strong>kd树更适用于训练实例数远大于空间维数时的k近邻搜索。当空间维数接近训练实例数时，它的效率会迅速下降，几乎接近线性扫描</strong>。</p><h1 id="dbscan聚类-基于密度的聚类">DBSCAN聚类（基于密度的聚类）</h1><h1 id="python实现">Python实现</h1><p>见<a href="./%E8%81%9A%E7%B1%BB%E5%AE%9E%E7%8E%B0.md">聚类实现</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://kebuaaa.github.io">爱编程的小明</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://kebuaaa.github.io/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">https://kebuaaa.github.io/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://kebuaaa.github.io" target="_blank">小明的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E8%81%9A%E7%B1%BB/">聚类</a></div><div class="post-share"><div class="social-share" data-image="/top_img/10054.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/" title="神经网络学习"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10003.webp" onerror='onerror=null,src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">神经网络学习</div></div><div class="info-2"><div class="info-item-1">发展 1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络，并将之命名为“感知器”(Perceptron)。 感知器有两个层次：输入层和输出层。 输入层里的“输入单元”只负责传输数据，不做计算。 输出层里的“输出单元”则需要对前面一层的输入进行计算。 感知器是当时首个可以学习的人工神经网络。Rosenblatt现场演示了其学习识别简单图像的过程。 按照不同的连接方式，神经网络可以分为： 感知器模型 多层感知机模型 前向多层神经网络 Hopfield神经网络 动态反馈网络 自组织神经网络等。 1986年，Rumelhar和Hinton等人提出了反向传播（Back...</div></div></div></a><a class="pagination-related" href="/%E4%BA%A7%E7%94%9F%E5%92%8C%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/" title="产生和加载数据集"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10048.webp" onerror='onerror=null,src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">产生和加载数据集</div></div><div class="info-2"><div class="info-item-1">速查表pdf 文本数据读写 python 读取文件常用的一种方式是 open()函数，open 里写文件的路径，读取后返回一个文件对象，借助 file_obj.read()函数可以调取出文件对象的数据（返回字符串），这种情况下要记得使用 close 函数把读取的文件关闭，以免造成损害。 另外一种读取文件的方法是利用 with 关键词来打开文件建立对象，打开的文件对象会在 with 区块内跳出时关闭文件对象。 逐行读取文件 逐行读取的第一种方法是直接通过循环对文件对象进行操作，每次读取出的一行行末的换行符可通过 restrip()函数删除 第二种方法是直接调用文件对象的 readline()方法，该方法将会返回一个字符串组成的列表，列表中每一个字符串包含一行，且有结尾换行符。通过对返回列表的操作可以实现对数据的组合 file_obj=open(&quot;D:/test.txt&quot;)data=file_obj.read()print(data)for line in file_obj: print(line) ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/" title="EM算法及其推广"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10048.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-17</div><div class="info-item-2">EM算法及其推广</div></div><div class="info-2"><div class="info-item-1">EM算法 对于一般概率模型的学习策略，我们往往会采取极大似然估计或者贝叶斯估计的方法对模型的参数进行估计，但是需要注意的是这种估计方法都是建立在待估参数全部为已经知道结果的参数的基础之上的(complete-data problem)。当模型中有隐变量/潜在变量（数据不可观测的变量）时，似然函数的最大化变得困难。这是就可以使用EM算法,EM算法是在不完全数据下求解MLE估计结果的一种近似求解方法，用迭代去逼近原来不完整数据问题的结果。EM算法主要分为两步： E:求期望(expectation) M:求极大(maximization) EM算法的核心思想是在既定样本数据下在因变量最有可能的分布状态下利用极大似然估计模型的参数。 算法导出 针对一个含有隐变量的概率模型，这里假设隐变量为Z，观测数据Y关于参数θ\thetaθ的对数似然函数为L(θ)L(\theta)L(θ): \begin{equation} \begin{aligned} L(\theta) &amp; = \log...</div></div></div></a><a class="pagination-related" href="/Entropy/" title="Entroy"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10057.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-05</div><div class="info-item-2">Entroy</div></div><div class="info-2"><div class="info-item-1">点击查看【bilibili】 1 章 绪论.pdf 2 章 离散信源及其信息测度.pdf intro 熵可以从随机变量状态需要的平均信息量角度理解, 也可以从描述统计力学中无序程度的度量角度理解。从平均信息量的角度来看，对于不确定性事件，可以用消除其不确定性需要的信息量(bit 数)来表示，这里表示成−log⁡pi-\log p_i−logpi​,而考虑到随机事件的不确定性，可以通过对信息量求期望得到某随机事件（随机变量）的信息熵，信息熵越大，则说明（消除随机性）需要的信息量越大，即不确定性越大。 一般来说，对于随机变量XXX，其信息熵定义如下: H(X)=−∑i=1np(xi)log⁡2p(xi)H(X)=-\sum\limits_{i=1}^{n}p(x_i)\log_2{p(x_i)} H(X)=−i=1∑n​p(xi​)log2​p(xi​) if p=0p=0p=0，then...</div></div></div></a><a class="pagination-related" href="/Logistic%20Regression/" title="Logistic Regression"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10044.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-17</div><div class="info-item-2">Logistic Regression</div></div><div class="info-2"><div class="info-item-1">当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，应该使用逻辑回归。这里，Y的值为0或1，它可以用以下方程表示： \begin{equation*} \begin{aligned} odds &amp;= \frac{p}{1-p}\\ &amp;=\frac{probability\hspace{5pt} of\hspace{5pt} event\hspace{5pt} occurrence}{probability\hspace{5pt} of\hspace{5pt} not\hspace{5pt} event...</div></div></div></a><a class="pagination-related" href="/SVM%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/" title="对偶问题（SVM）"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10029.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-04</div><div class="info-item-2">对偶问题（SVM）</div></div><div class="info-2"><div class="info-item-1">Duality (optimization) In mathematical optimization theory, duality or the duality principle is the principle that optimization problems may be viewed from either of two perspectives, the primal problem or the dual problem. The solution to the dual problem provides a lower bound to the solution of the primal (minimization) problem.However in general the optimal values of the primal and dual problems need not be equal. Their difference is called the duality gap. For convex optimization...</div></div></div></a><a class="pagination-related" href="/%E5%86%B3%E7%AD%96%E6%A0%91/" title="决策树模型"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10001.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-12</div><div class="info-item-2">决策树模型</div></div><div class="info-2"><div class="info-item-1">人们的决策过程是一个类似“观察因素A的情况，再根据A的情况观察因素B的情况”的形式，从而形成一种树状结构。决策树学习是模仿人类这一结构化决策过程而发展起来的一种有监督机器学习方法。 它可以被认为是if-then规则的集合，也可以被认为是定义在特征空间和类空间上的条件概率分布。 模型具有可读性 分类速度快 决策树的思想主要来源于Quinlan在1986年提出的ID3和1993提出的C4.5算法，以及由Breiman等人1984年提出的CART算法。 模型 决策树学习本质上是从训练数据集中归纳出一组分类规则或者条件概率模型（在节点处取条件概率最大的进行分类）。决策树问题一般可以分成特征选择、决策树生成、剪枝三部分。 特征选择：通过建立一个函数来衡量特征划分的效果 生成：递归构造决策树的过程 剪枝：递归产生的决策树往往会递归到不能分类为止，这会导致出现过拟合现象，因此需要已经生成的决策树进行剪枝(pruning)，一般是通过极小化决策树整体的损失函数(loss function)或者代价函数(cost...</div></div></div></a><a class="pagination-related" href="/%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95/" title="分类方法"><img class="cover" src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10036.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-06</div><div class="info-item-2">分类方法</div></div><div class="info-2"><div class="info-item-1">线性分类方法 感知机和线性判别分析/Fisher分析是非常经典的硬分类线性模型，模型提出都比较早。 感知机 感知机是二类分类的线性分类模型。 感知机只在求出线性可分的分类超平面，通过梯度下降法对损失函数极小化建立感知机模型。 感知机1957年由Rosenblatt提出，是神经网络和支持向量机的基础 模型 输入空间是实例向量组成的空间，输出空间是-1和+1（正负两类）。建立如下函数： \begin{align*} f(x)&amp;=sign(\omega \cdot x+b)\\ \omega&amp;:weight\quad or\quad weight\quad...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/img/avatar.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">爱编程的小明</div><div class="author-info-description">只要不折腾，万般可将就</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">100</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kebuAAA"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/kebuAAA" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/2945190789@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/img/wechat.webp" target="_blank" title="欢迎交流"><i class="fa-brands fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">如网页加载较慢请尝试魔法上网，博客图文可能无关可以忽略</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">相似度的计算方法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">聚类分析方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%92%E5%88%86%E6%B3%95-partitioning-method"><span class="toc-number">2.1.</span> <span class="toc-text">划分法(Partitioning Method)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B1%82%E6%AC%A1%E6%B3%95-hierarchical-method"><span class="toc-number">2.2.</span> <span class="toc-text">层次法(Hierarchical Method)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%AF%86%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95-density-based-method"><span class="toc-number">2.3.</span> <span class="toc-text">基于密度的方法(Density-based Method)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BD%91%E6%A0%BC%E7%9A%84%E6%96%B9%E6%B3%95-grid-based-method"><span class="toc-number">2.4.</span> <span class="toc-text">基于网格的方法(Grid-based Method)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">聚类分析的过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">3.1.</span> <span class="toc-text">聚类算法的模型评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E9%80%89%E6%8B%A9%E4%BD%BF%E7%94%A8inertia%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-number">3.1.1.</span> <span class="toc-text">不选择使用Inertia进行评估的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E5%B7%B2%E7%9F%A5%E7%9A%84%E6%97%B6%E5%80%99"><span class="toc-number">3.1.2.</span> <span class="toc-text">当真实标签已知的时候</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E6%9C%AA%E7%9F%A5%E7%9A%84%E6%97%B6%E5%80%99"><span class="toc-number">3.1.3.</span> <span class="toc-text">当真实标签未知的时候</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0-silhouette-coefficient"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">轮廓系数(Silhouette Coefficient)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%A1%E6%9E%97%E6%96%AF%E5%9F%BA%E5%93%88%E6%8B%89%E5%B7%B4%E6%96%AF%E6%8C%87%E6%95%B0-calinski-harabaz-index"><span class="toc-number">3.1.3.2.</span> <span class="toc-text">卡林斯基哈拉巴斯指数（Calinski-harabaz Index）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%B1%E7%BB%B4%E6%96%AF-%E5%B8%83%E5%B0%94%E4%B8%81%E6%8C%87%E6%95%B0"><span class="toc-number">3.1.3.3.</span> <span class="toc-text">就维斯-布尔丁指数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%83%E5%8F%98%E7%9F%A9%E9%98%B5"><span class="toc-number">3.1.3.4.</span> <span class="toc-text">权变矩阵</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#k-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">K-means聚类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E8%B4%A8%E5%BF%83%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">4.1.</span> <span class="toc-text">初始质心的选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#k%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9%E4%BE%9D%E6%8D%AE"><span class="toc-number">4.2.</span> <span class="toc-text">K值的选择依据</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#knn"><span class="toc-number">5.</span> <span class="toc-text">KNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.1.</span> <span class="toc-text">模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F"><span class="toc-number">5.1.1.</span> <span class="toc-text">距离度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">5.1.2.</span> <span class="toc-text">k值的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%86%B3%E7%AD%96%E4%BE%9D%E6%8D%AE"><span class="toc-number">5.1.3.</span> <span class="toc-text">分类决策依据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%E7%AE%97%E6%B3%95-kd%E6%A0%91"><span class="toc-number">5.2.</span> <span class="toc-text">具体实现算法–kd树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2"><span class="toc-number">5.2.1.</span> <span class="toc-text">搜索</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#dbscan%E8%81%9A%E7%B1%BB-%E5%9F%BA%E4%BA%8E%E5%AF%86%E5%BA%A6%E7%9A%84%E8%81%9A%E7%B1%BB"><span class="toc-number">6.</span> <span class="toc-text">DBSCAN聚类（基于密度的聚类）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#python%E5%AE%9E%E7%8E%B0"><span class="toc-number">7.</span> <span class="toc-text">Python实现</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10029.webp" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="Lasso回归"></a><div class="content"><a class="title" href="/Lasso%E5%9B%9E%E5%BD%92/" title="Lasso回归">Lasso回归</a><time datetime="2023-11-14T16:00:00.000Z" title="更新于 2023-11-15 00:00:00">2023-11-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/岭回归_20231109082818.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="岭回归"></a><div class="content"><a class="title" href="/%E5%B2%AD%E5%9B%9E%E5%BD%92/" title="岭回归">岭回归</a><time datetime="2023-11-07T16:00:00.000Z" title="更新于 2023-11-08 00:00:00">2023-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/优雅论文排版_20230921093206.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="优雅论文排版"></a><div class="content"><a class="title" href="/%E4%BC%98%E9%9B%85%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/" title="优雅论文排版">优雅论文排版</a><time datetime="2023-09-20T16:00:00.000Z" title="更新于 2023-09-21 00:00:00">2023-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/多元统计分析_多元正态曲线.png" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="多元统计分析"></a><div class="content"><a class="title" href="/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/" title="多元统计分析">多元统计分析</a><time datetime="2023-06-16T02:22:54.000Z" title="更新于 2023-06-16 10:22:54">2023-06-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Hypothesis%20testing/" title="假设检验"><img src="https://gcore.jsdelivr.net/gh/kebuAAA/Picloud@main/img/loading.gif" data-lazy-src="/top_img/10008.webp" onerror='this.onerror=null,this.src="https://images.pexels.com/photos/374918/pexels-photo-374918.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=600"' alt="假设检验"></a><div class="content"><a class="title" href="/Hypothesis%20testing/" title="假设检验">假设检验</a><time datetime="2023-05-09T02:34:00.000Z" title="更新于 2023-05-09 10:34:00">2023-05-09</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"></div><script src="/Scripts/js/beijing.js"></script><script src="/Scripts/js/foot_style.js"></script><script src="/Scripts/js/fireworks.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"])',selectors:["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"],cacheBust:!1,analytics:!1,scrollRestoration:!1});const e=e=>{e&&Object.values(e).forEach((e=>e()))};document.addEventListener("pjax:send",(()=>{btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");const t=document.body.classList;t.contains("read-mode")&&t.remove("read-mode"),e(window.globalFn.pjaxSend)})),document.addEventListener("pjax:complete",(()=>{btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach((e=>{const t=document.createElement("script"),n=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach((e=>t.setAttribute(e.name,e.value))),t.appendChild(document.createTextNode(n)),e.parentNode.replaceChild(t,e)})),e(window.globalFn.pjaxComplete)})),document.addEventListener("pjax:error",(e=>{if(404===e.request.status){window.location.href=e.request.responseURL}}))})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","2s"),arr[i].setAttribute("data-wow-delay","0.5s"),arr[i].setAttribute("data-wow-offset","100"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow_init.js"></script></body></html>